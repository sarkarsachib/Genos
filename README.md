# Screen Capture and OCR Android Application

This Android application implements a comprehensive screen capture and OCR pipeline that leverages the MediaProjection API for screen capture, ML Kit for OCR processing, accessibility tree integration for UI element detection, and is ready for Gemini AI integration.

## üéØ Key Features

- **MediaProjection API Integration**: Real-time screen capture with user consent flow
- **Dual OCR Support**: ML Kit Text Recognition and Tesseract via tess-two
- **Accessibility Tree Integration**: Real-time UI element hierarchy and properties extraction
- **Screen State Aggregation**: Combined payload of screenshot, OCR text, and UI elements
- **Lifecycle Management**: Automatic stopping when screen is off or app is backgrounded
- **Comprehensive Testing**: Unit tests for all core components
# GENOS Overlay System

A comprehensive Android application implementing a WindowManager-based overlay with input emulation and command execution capabilities.

## Overview

This project implements a sophisticated Android system that provides:

1. **WindowManager Overlay (HUD)** - A persistent floating overlay showing GENOS status, current app, and Gemini decision summary
2. **Input Emulator Service** - Rootless input emulation using AccessibilityService with dispatchGesture for taps, swipes, typing
3. **Command Executor** - Sequential execution of Gemini action plans with error reporting and safeguards
# Genos Core - AI Assistant Framework

An Android application framework for building AI-powered assistants with screen capture, accessibility services, and intelligent input processing.

## Project Overview

Genos Core is designed to provide a foundation for building AI assistants that can:
- Monitor screen content via Accessibility Services
- Capture screenshots using MediaProjection API
- Process text using ML Kit and Tesseract OCR
- Display overlay interfaces for user interaction
- Process and respond to user input

## Requirements

- **Minimum SDK**: API 24 (Android 7.0)
- **Target SDK**: API 34 (Android 14)
- **Language**: Kotlin (with Java compatibility)
- **Build Tool**: Gradle 8.2.0+
- **Kotlin Version**: 1.9.20

## Building the Project

### Prerequisites
- Android Studio Arctic Fox or later
- JDK 17
- Android SDK with API 24+ installed

### Build Commands

Build debug APK:
```bash
./gradlew assembleDebug
```

Build release APK:
```bash
./gradlew assembleRelease
```

Install on connected device:
```bash
./gradlew installDebug
```

Run tests:
```bash
./gradlew test
```

## Architecture

### Package Structure

```
ai.genos.core/
‚îú‚îÄ‚îÄ service/               # Android Services
‚îÇ   ‚îú‚îÄ‚îÄ GenosAccessibilityService.kt    # Accessibility service for screen monitoring
‚îÇ   ‚îú‚îÄ‚îÄ ScreenCaptureService.kt         # Foreground service for screen capture
‚îÇ   ‚îú‚îÄ‚îÄ OverlayService.kt               # Service for managing overlays
‚îÇ   ‚îî‚îÄ‚îÄ InputProcessingService.kt       # Service for processing user input
‚îÇ
‚îú‚îÄ‚îÄ overlay/               # Overlay UI components
‚îÇ   ‚îî‚îÄ‚îÄ OverlayManager.kt               # Manages overlay windows
‚îÇ
‚îú‚îÄ‚îÄ input/                 # Input processing
‚îÇ   ‚îî‚îÄ‚îÄ InputProcessor.kt               # Processes text and voice input
‚îÇ
‚îú‚îÄ‚îÄ capture/               # Screen capture and OCR
‚îÇ   ‚îú‚îÄ‚îÄ ScreenCaptureManager.kt         # Handles screen capture via MediaProjection
‚îÇ   ‚îî‚îÄ‚îÄ TextRecognizer.kt               # OCR using ML Kit and Tesseract
‚îÇ
‚îî‚îÄ‚îÄ ui/                    # User interface
    ‚îú‚îÄ‚îÄ MainActivity.kt                 # Main entry point
    ‚îú‚îÄ‚îÄ SettingsActivity.kt             # Settings and configuration
    ‚îî‚îÄ‚îÄ theme/                          # Jetpack Compose theme
```

## Key Technologies

### Core Android Components
- **Accessibility Service**: Monitors screen content and UI events
- **MediaProjection**: Captures screen content
- **Foreground Service**: Keeps capture service running

### Jetpack Components
- **Compose**: Modern declarative UI framework
- **Lifecycle**: Lifecycle-aware components
- **WorkManager**: Background task scheduling
- **Room**: Local database (future use)
- **Navigation**: App navigation

### ML/OCR
- **ML Kit Text Recognition**: Google's on-device text recognition
- **Tesseract**: Open-source OCR engine

## Permissions

The app requires the following permissions:

### Runtime Permissions
- `SYSTEM_ALERT_WINDOW`: Display overlay windows
- `FOREGROUND_SERVICE`: Run foreground services
- `FOREGROUND_SERVICE_MEDIA_PROJECTION`: Screen capture in foreground
- `POST_NOTIFICATIONS`: Display notifications (Android 13+)

### Special Permissions
- `BIND_ACCESSIBILITY_SERVICE`: Accessibility service binding
- `WRITE_SECURE_SETTINGS`: System settings modification (placeholder, requires system signature)

## Phase 1 - Initial Setup (Current)

### Completed
‚úÖ Project structure and Gradle configuration
‚úÖ AndroidManifest with all required permissions
‚úÖ Base service implementations (stubs)
‚úÖ Package structure for modules
‚úÖ Jetpack Compose UI setup
‚úÖ Build system configuration

### Next Steps
- [ ] Implement accessibility service event handling
- [ ] Implement MediaProjection screen capture
- [ ] Integrate ML Kit text recognition
- [ ] Integrate Tesseract OCR
- [ ] Implement overlay window management
- [ ] Add permission request flows
- [ ] Implement input processing pipeline

## Development Guidelines

### Code Style
- Follow Kotlin coding conventions
- Use Jetpack Compose for UI
- Leverage coroutines for async operations
- Use dependency injection (future enhancement)

### Testing
- Write unit tests for business logic
- Write instrumentation tests for UI
- Test on devices with API 24+ and 34

### Architecture Patterns
- MVVM pattern for UI components
- Repository pattern for data access
- Service-oriented architecture for background tasks

## Permissions Setup

### Accessibility Service
Users must manually enable the accessibility service:
1. Go to Settings ‚Üí Accessibility
2. Find "Genos Accessibility Service"
3. Enable the service

### Overlay Permission
Users must grant overlay permission:
1. Go to Settings ‚Üí Apps ‚Üí Genos Core ‚Üí Display over other apps
2. Enable "Allow display over other apps"

### Screen Capture
Screen capture requires user consent at runtime via MediaProjection API.

## Troubleshooting

### Build Issues
- Ensure you have JDK 17 installed
- Run `./gradlew clean` before building
- Sync Gradle files in Android Studio

### Service Issues
- Check that all permissions are granted
- Verify services are declared in AndroidManifest.xml
- Check logcat for service lifecycle events

## License

[Add your license information here]

## Contributing

[Add contribution guidelines here]
# Gemini AI Client

A Kotlin-based client for interacting with Gemini AI services using Retrofit and OkHttp.

## Features

- **Retrofit-based API client** with OkHttp integration
- **Exponential backoff** for rate limiting and retry logic
- **API key interceptor** for secure authentication
- **Request/response compression** for large payloads (screenshots, node trees)
- **Typed action descriptors** (Tap, Swipe, Type actions)
- **Health check** functionality
- **Configuration management** (BuildConfig, environment variables, properties files)
- **Comprehensive unit tests** with MockK
- **Coroutines support** for asynchronous operations

## Module Structure

```
ai/gemini/
‚îú‚îÄ‚îÄ src/main/kotlin/com/example/ai/gemini/
‚îÇ   ‚îú‚îÄ‚îÄ api/                  # API service and client
‚îÇ   ‚îú‚îÄ‚îÄ config/               # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ di/                   # Dependency injection
‚îÇ   ‚îú‚îÄ‚îÄ models/               # Request/response models
‚îÇ   ‚îú‚îÄ‚îÄ repository/           # Repository layer
‚îÇ   ‚îú‚îÄ‚îÄ serialization/        # Compression utilities
‚îÇ   ‚îî‚îÄ‚îÄ sample/               # Usage examples
‚îî‚îÄ‚îÄ src/test/kotlin/com/example/ai/gemini/
    ‚îú‚îÄ‚îÄ api/                  # API tests
    ‚îú‚îÄ‚îÄ repository/           # Repository tests
    ‚îú‚îÄ‚îÄ integration/          # Integration tests
    ‚îî‚îÄ‚îÄ test/                 # Test utilities
```

## Models

### Request Models

- `ScreenState`: Contains OCR text, node tree JSON, and optional screenshot
- `ActionRequest`: Main request payload with screen state and instruction
- `RequestConfig`: Configuration for AI parameters (temperature, max tokens, etc.)

### Response Models

- `ActionResponse`: Contains list of actions, confidence, reasoning, and model version
- `ActionDescriptor`: Sealed class with concrete implementations:
  - `TapAction`: Tap gesture with coordinates
  - `SwipeAction`: Swipe gesture with start/end coordinates
  - `TypeAction`: Text input action
- `ErrorResponse`: Standardized error format

## Usage

### Basic Setup

```kotlin
// Initialize configuration
GeminiConfig.baseUrl = "https://api.gemini.example.com/"
GeminiConfig.apiKey = "your-api-key"

// Create client and repository
val geminiClient = GeminiModule.provideGeminiClient()
val geminiRepository = GeminiModule.provideGeminiRepository(geminiClient)
```

### Plan Actions

```kotlin
val screenState = ScreenState(
    ocrText = "Login Screen",
    nodeTreeJson = "{\"nodes\": [...]}",
    screenshotBase64 = "base64-encoded-image"
)

val instruction = "Login with username and password"

val result = geminiRepository.planActions(screenState, instruction)

if (result.isSuccess) {
    val actions = result.getOrNull()
    actions?.forEach { action ->
        when (action) {
            is TapAction -> performTap(action.x, action.y)
            is SwipeAction -> performSwipe(action.startX, action.startY, action.endX, action.endY)
            is TypeAction -> performType(action.text)
        }
    }
}
```

### With Compression

```kotlin
val result = geminiRepository.planActionsWithCompression(screenState, instruction)
```

### Health Check

```kotlin
val healthResult = geminiRepository.healthCheck()
if (healthResult.isSuccess && healthResult.getOrNull() == true) {
    println("Service is healthy")
}
```

## Configuration

### BuildConfig

```kotlin
object GeminiConfig {
    object BuildConfig {
        const val DEBUG = true
        const val GEMINI_BASE_URL = "https://api.gemini.example.com/"
        const val GEMINI_API_KEY = "default-api-key"
    }
}
```

### Environment Variables

```bash
export GEMINI_BASE_URL="https://api.gemini.example.com/"
export GEMINI_API_KEY="your-api-key"
```

### Properties File

Create `gemini.properties` in assets:

```properties
gemini.baseUrl=https://api.gemini.example.com/
gemini.apiKey=your-api-key
gemini.timeoutSeconds=30
gemini.enableLogging=true
gemini.enableCompression=true
```

## Error Handling

The client uses Kotlin's `Result` type for error handling:

```kotlin
val result = geminiRepository.planActions(screenState, instruction)

if (result.isFailure) {
    val exception = result.exceptionOrNull()
    if (exception is GeminiClient.GeminiApiException) {
        val errorResponse = exception.errorResponse
        println("Error: ${errorResponse.error}")
        println("Message: ${errorResponse.message}")
        println("Status: ${errorResponse.statusCode}")
    }
}
```

## Testing

Run tests with:

```bash
./gradlew test
```

### Test Coverage

- `GeminiClientTest`: Tests API client functionality
- `GeminiRepositoryTest`: Tests repository layer
- `GeminiIntegrationTest`: Tests complete workflow

## Dependencies

- Kotlin 1.9.0
- Kotlinx Coroutines 1.7.3
- Kotlinx Serialization 1.6.0
- Retrofit 2.9.0
- OkHttp 4.11.0
- MockK 1.13.5 (for testing)

## Build

```bash
./gradlew build
```

## License

MIT License

## Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

## Support

For issues and feature requests, please use the GitHub issue tracker.
# Android Project Scaffolding

This Android project implements a complete overlay UI and integration harness for GENOS (Generic Enhanced Navigation and Operation System) using Accessibility Service and WindowManager APIs.

## Overview

GENOS provides a persistent overlay that visualizes touch targets, gestures, and system status while enabling automated command execution across any Android application. The system includes:

- **Persistent Overlay UI** - Floating window showing GENOS status and controls
- **Command Pipeline** - Screen reading ‚Üí command interpretation ‚Üí input execution ‚Üí status feedback
- **Touch Visualization** - Real-time gesture highlighting with animated feedback
- **OCR Integration** - ML Kit-powered text recognition with instant results
- **Accessibility Integration** - Complete automation of any Android app

## Architecture

### Core Components

- **GenosStatus** - System status model tracking automation state, current app, and Gemini decisions
- **GeminiActionPlan** - Action plan model containing sequence of ActionCommands
- **ActionCommand** - Individual command model (tap, swipe, type, wait, etc.)
- **CommandParameters** - Parameter container for action commands
- **OverlayService** - WindowManager-based floating HUD with drag controls
- **InputEmulatorService** - AccessibilityService for rootless input emulation
- **CommandExecutor** - Sequential command execution with timeout and error handling
- **MainActivity** - Debug UI for testing all components

### Features Implemented

#### 1. WindowManager Overlay
- ‚úÖ Floating HUD with drag handle
- ‚úÖ Real-time status display (GENOS state, current app, Gemini decision)
- ‚úÖ Controls for automation toggle and test execution
- ‚úÖ Permission handling for overlay display
- ‚úÖ Auto-positioning and drag functionality

#### 2. Input Emulator Service
- ‚úÖ AccessibilityService integration with `dispatchGesture`
- ‚úÖ Tap gestures at specified coordinates
- ‚úÖ Long press gestures
- ‚úÖ Swipe/scroll gestures with custom paths
- ‚úÖ Text input via `ACTION_SET_TEXT` and IME fallback
- ‚úÖ System gestures (back, home, recents)
- ‚úÖ Timeout handling and error reporting

#### 3. Command Executor
- ‚úÖ Sequential execution of action plans
- ‚úÖ Timeout safeguards (30-second default)
- ‚úÖ User cancellation capability
- ‚úÖ Error reporting with continue/stop logic
- ‚úÖ Execution callbacks for UI updates
- ‚úÖ Mock plan execution for testing

#### 4. Integration Features
- ‚úÖ Service binding between InputEmulator and CommandExecutor
- ‚úÖ Real-time overlay updates during execution
- ‚úÖ Manual command injection via debug UI
- ‚úÖ Custom command parsing (tap(x,y), swipe(x1,y1,x2,y2), type(text))

## Usage Instructions

### Setup

1. **Grant Overlay Permission**
   - Enable "Overlay Permission" in the app
   - Grant permission in system dialog

2. **Enable Accessibility Service**
   - Toggle "Accessibility Service" in the app
   - Enable "GENOS Input Emulator Service" in system settings

3. **Test Individual Commands**
   - Use "Test Tap", "Test Swipe", "Test Type" buttons
   - Try custom commands like:
     - `tap(200,400)` - Tap at screen coordinates
     - `swipe(100,500,300,300,400)` - Swipe from (100,500) to (300,300) over 400ms
     - `type(Hello World!)` - Type text into focused field

4. **Execute Mock Gemini Plan**
   - Click "Execute Mock Gemini Plan" to run a complete sequence
   - Observe real device actions (home, wait, swipe)

### Acceptance Criteria Validation

‚úÖ **Overlay Toggle**: Overlay can be shown/hidden with toggle switch  
‚úÖ **Manual Command Injection**: Debug UI supports real taps/swipes/types  
‚úÖ **Real Actions**: Executing mocked Gemini response results in visible on-device actions  
‚úÖ **Input Emulation**: Rootless gesture dispatch via AccessibilityService  
‚úÖ **Command Execution**: Sequential plan execution with error handling  
‚úÖ **Status Display**: Real-time GENOS status and app information  

## Technical Details

### Permissions Required
- `SYSTEM_ALERT_WINDOW` - For overlay display
- `BIND_ACCESSIBILITY_SERVICE` - For input emulation
- `INTERNET` - For future Gemini integration

### API Requirements
- Minimum SDK: 26 (Android 8.0)
- Target SDK: 34 (Android 14)
- Uses `dispatchGesture()` API (API 24+)

### Key Technologies
- **WindowManager** - Floating overlay implementation
- **AccessibilityService** - Rootless input emulation
- **GestureDescription** - Modern gesture API
- **CommandExecutor Pattern** - Sequential action execution
- **Service Binding** - Inter-service communication

## Project Structure

```
com/genos/overlay/
‚îú‚îÄ‚îÄ GenosOverlayApplication.java     # Application class
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îî‚îÄ‚îÄ MainActivity.java             # Debug UI and main entry point
‚îú‚îÄ‚îÄ service/
‚îÇ   ‚îú‚îÄ‚îÄ OverlayService.java           # WindowManager overlay
‚îÇ   ‚îú‚îÄ‚îÄ InputEmulatorService.java     # Accessibility input emulation
‚îÇ   ‚îî‚îÄ‚îÄ CommandExecutor.java          # Action plan execution
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ GenosStatus.java              # System status model
‚îÇ   ‚îú‚îÄ‚îÄ GeminiActionPlan.java         # Action plan model
‚îÇ   ‚îú‚îÄ‚îÄ ActionCommand.java            # Command model
‚îÇ   ‚îî‚îÄ‚îÄ CommandParameters.java        # Command parameters
‚îî‚îÄ‚îÄ receiver/
    ‚îî‚îÄ‚îÄ BootReceiver.java             # Boot completion handler
```

## Future Enhancements

1. **Gemini Integration** - Real Gemini AI decision making
2. **Advanced UI Targeting** - Element-based interactions
3. **Recording/Replay** - User action recording system
4. **Configuration Management** - User preferences and settings
5. **Security Features** - Permission validation and safety checks
6. **Performance Optimization** - Gesture batching and optimization

## Building and Testing

The project uses standard Android build tools:

```bash
# Build APK
./gradlew assembleDebug

# Install on device
adb install app/build/outputs/apk/debug/app-debug.apk
```

## Notes

- This implementation provides a complete foundation for the GENOS overlay system
- All core features are implemented and functional
- The system is ready for integration with actual Gemini AI
- Extensive logging and error handling ensures reliability
- The debug UI allows comprehensive testing of all features
The project contains the following packages in `app/src/main/java/com/example/androidproject/`:

- **`accessibility`**: AccessibilityService implementation for UI tree inspection and input injection  
- **`vision`**: Screen capture and ML Kit OCR integration
- **`command`**: Command parsing and execution system (tap, swipe, scroll, input, wait)
- **`overlay`**: WindowManager-based persistent overlay with gesture visualization
- **`ai`**: Placeholder for LLM integration (Gemini API ready)

### Integration Pipeline

```
Screen Content ‚Üí Accessibility Service ‚Üí UI Hierarchy
                    ‚Üì
Command Input ‚Üí Command Processor ‚Üí Parsed Command
                    ‚Üì
Command Executor ‚Üí Gesture/Input ‚Üí Accessibility Actions
                    ‚Üì
Gesture Overlay ‚Üê Visual Feedback ‚Üê Status Updates
```

## Key Features

### 1. Persistent Overlay (`overlay/OverlayService.kt`)
- **Always-on-top** using `TYPE_APPLICATION_OVERLAY` across all apps
- **Real-time status** showing current app, automation state, and last action
- **Touch visualization** with animated ripples, swipe paths, and scroll indicators
- **Toggle controls** for start/stop automation, OCR requests, and UI tree display

### 2. Command Processing (`command/`)
- **Natural language commands**: `tap 500 500`, `swipe 100 1000 700 500`, `scroll down`
- **Batch execution**: Parse and execute multiple commands in sequence
- **Error handling**: Graceful handling of invalid commands and edge cases
- **Visual feedback**: Every command triggers overlay status and touch visualization updates

### 3. Touch Visualization (`overlay/GestureOverlayView.kt`)
- **Instant feedback**: Pink ripple effect for taps, green/red circles for swipe start/end
- **Gesture trails**: Animated paths showing swipe directions and distances
- **Scroll indicators**: Multiple parallel lines showing scroll direction
- **Automatic cleanup**: Visualizations fade after 2-3 seconds

### 4. OCR Integration (`vision/`, ML Kit)
- **On-demand text recognition** via overlay button
- **Real-time results** displayed directly in overlay UI
- **UI tree display** showing accessibility node hierarchy for screen reading

## üèóÔ∏è Architecture

The application follows a modular architecture with four main components:

### Core Components

1. **ScreenCaptureManager** (`com.example.androidproject.vision.ScreenCaptureManager`)
   - Handles MediaProjection API integration
   - Periodic screenshot capture triggered by screen changes
   - Memory buffer management for captured Bitmaps
   - User consent flow via `startActivityForResult`
### Environment Variables
The project uses `buildConfig` fields for sensitive data. Currently configured in `app/build.gradle.kts`:

- `GEMINI_API_KEY`: Placeholder for Gemini AI integration
- `GEMINI_ENDPOINT`: Gemini API endpoint

### Required Permissions
- `SYSTEM_ALERT_WINDOW` - Overlay display over other apps
- `BIND_ACCESSIBILITY_SERVICE` - Accessibility automation and UI inspection  
- `FOREGROUND_SERVICE` & `FOREGROUND_SERVICE_MEDIA_PROJECTION` - Background operation
- `INTERNET` - ML Kit and AI API access

## Usage

### 1. First Launch
1. Launch the app
2. Tap **"Enable Overlay & Accessibility Permissions"**
3. Grant overlay permission when prompted
4. Enable **"GENOS Accessibility Service"** in Settings ‚Üí Accessibility
5. Return to app and tap **"Launch GENOS Overlay"**

### 2. Basic Commands
The overlay provides control buttons, or send commands via the app console:

```
tap 500 500          # Tap at coordinates (x, y)
swipe 100 1000 700 500 # Swipe from (x1, y1) to (x2, y2)
scroll down          # Scroll down on scrollable content
ocr                  # Trigger OCR on current screen
tree                 # Show/hide UI tree hierarchy
```

### 3. Integration Demo
**Complete automation pipeline:**
1. Navigate to target app
2. Tap **"Tree"** button to inspect UI hierarchy
3. Identify target coordinates from UI tree
4. Send tap command: `tap 300 800`
5. **Observe**: Visual feedback on overlay + action execution
6. Trigger OCR: `ocr`
7. **Observe**: Recognized text appears in overlay

### 4. Overlay Controls
- **Start/Stop**: Toggle automation monitoring state
- **OCR**: Perform text recognition on current screen
- **Tree**: Show/hide detailed UI tree for debugging

2. **OcrProcessor** (`com.example.androidproject.vision.OcrProcessor`)
   - ML Kit Text Recognition with bounding box extraction
   - Regional OCR processing for focused areas
   - Text block, line, and element hierarchy extraction
   - Coroutine-based async processing

3. **TesseractOcrProcessor** (`com.example.androidproject.vision.TesseractOcrProcessor`)
   - Alternative OCR implementation using Tesseract
   - Configurable recognition parameters
   - Regional processing capabilities
   - Asset-based language data management

4. **ScreenStateAggregator** (`com.example.androidproject.vision.ScreenStateAggregator`)
   - Screenshot persistence with URI management
   - OCR text and bounding box extraction
   - UI element processing and hierarchy
   - Aggregated payload creation for Gemini AI
   - Storage cleanup and management

5. **Accessibility Service** (`com.example.androidproject.accessibility.MyAccessibilityService`)
   - Real-time accessibility tree monitoring
   - UI element bounding boxes and properties
   - View hierarchy path tracking
   - Interactive element detection

## üöÄ Quick Start

### Basic Usage

```kotlin
// Initialize the coordinator
val coordinator = ScreenCaptureCoordinator(context, activity)

// Request permissions and start pipeline
val initialized = coordinator.initializeScreenCapture()
if (initialized) {
    coordinator.startPipeline()
}

// Trigger manual capture
val result = coordinator.triggerManualCapture()
when (result) {
    is ScreenStateResult.Success -> {
        val screenState = result.screenState
        // Process aggregated data
        processScreenState(screenState)
    }
    is ScreenStateResult.Error -> {
        Log.e("Capture", "Error: ${result.message}")
    }
}
```

### OCR Engine Selection

```kotlin
// Use ML Kit OCR (default)
val mlKitProcessor = OcrProcessor()
val mlKitResult = mlKitProcessor.processImage(bitmap)

// Use Tesseract OCR
val tesseractProcessor = TesseractOcrProcessor(context)
val initialized = tesseractProcessor.initialize()
if (initialized) {
    val tesseractResult = tesseractProcessor.processImage(bitmap)
}
```

## üì± User Consent Flow

The application implements a comprehensive consent flow:

1. **Accessibility Permission**: Users enable the service via Settings
2. **Screen Capture Consent**: Users grant MediaProjection permission
3. **Lifecycle Management**: Automatic cleanup and stopping

## üß™ Testing

The project includes comprehensive unit tests:

```bash
# Run unit tests
./gradlew test

# Run integration tests
./gradlew connectedAndroidTest
```

Test coverage includes:
- OCR processor initialization and processing
- Screen state aggregation
- Data structure validation
- Result type handling
- Performance comparison between OCR engines

## üìã Permissions

The app requests the following permissions:

- `INTERNET` - For network operations
- `FOREGROUND_SERVICE` - For background service operation
- `FOREGROUND_SERVICE_MEDIA_PROJECTION` - For MediaProjection API (Android 14+)
- `SYSTEM_ALERT_WINDOW` - For overlay functionality
- `WRITE_EXTERNAL_STORAGE` - For screenshot persistence
- `BIND_ACCESSIBILITY_SERVICE` - For UI tree extraction

## üîß Dependencies

Key dependencies include:

- **ML Kit Text Recognition**: Primary OCR processing
- **Tesseract (tess-two)**: Alternative OCR implementation
- **Kotlin Coroutines**: Async processing and flow management
- **Compose UI**: Modern Android UI framework
- **Accessibility Service**: UI tree extraction
- **MediaProjection API**: Screen capture functionality

## üìä Data Structures

### ScreenState Result
```kotlin
data class ScreenState(
    val screenshotUri: Uri,                    // Persistent screenshot location
    val timestamp: Long,                       // Capture timestamp
    val ocrText: String,                       // Extracted text content
    val ocrBoundingBoxes: List<TextBoundingBox>, // Text with positions
    val uiElements: List<UiElement>,           // UI hierarchy data
    val metadata: ScreenMetadata              // Processing metadata
)
```

### OCR Result
```kotlin
sealed class OcrResult {
    data class Success(val textBlocks: List<TextBlock>) : OcrResult()
    data class Error(val message: String) : OcrResult()
}
```

## üéØ Acceptance Criteria Fulfillment

‚úÖ **ScreenCaptureManager with MediaProjection API**: Implemented with proper lifecycle management

‚úÖ **Periodic screenshots triggered by screen changes**: Real-time capture with memory buffer management

‚úÖ **ML Kit Text Recognition integration**: Complete OCR processing with bounding boxes

‚úÖ **Tesseract alternative OCR**: Full implementation with regional processing

‚úÖ **Accessibility tree integration**: Real-time UI element hierarchy extraction

‚úÖ **ScreenStateAggregator**: Comprehensive data packaging for Gemini AI

‚úÖ **User consent flow**: startActivityForResult implementation

‚úÖ **Lifecycle management**: Automatic stopping on screen off

‚úÖ **Bitmap decoding**: Proper ImageReader handling and bitmap processing

‚úÖ **Text snippets with bounding boxes**: Complete OCR result extraction

‚úÖ **Aggregated payload for transmission**: Ready-to-send data structure

## üîÑ Example Usage Scenarios

See `ScreenCaptureExampleUsage.kt` for comprehensive examples including:

- Basic ML Kit OCR pipeline
- Tesseract OCR pipeline
- Regional OCR processing
- Complete pipeline with accessibility
- Performance comparison between OCR engines

## üìö Documentation

- [Screen Capture Implementation](SCREEN_CAPTURE_README.md) - Detailed implementation guide
- [API Documentation](docs/) - Comprehensive API reference
- [Testing Guide](docs/testing.md) - Testing strategies and examples

## ü§ù Contributing

1. Follow the existing code style and patterns
2. Add unit tests for new functionality
3. Update documentation for API changes
4. Ensure all acceptance criteria are met

## üìÑ License

This project is provided as-is for educational and development purposes.

---

**Note**: This implementation provides a complete foundation for screen capture and OCR processing. For production use, consider adding additional features like:
- Real-time compression optimization
- Selective region capture for performance
- Enhanced error handling and recovery
- Integration with Gemini API for intelligent processing
- Advanced filtering and noise reduction
### Prerequisites
- JDK 17 or higher
- Android Studio Hedgehog or newer
- Android device/emulator with API 26+ (Android 8.0)

### Build Commands
```bash
# Build APK
./gradlew build

# Install debug version
./gradlew installDebug

# Run instrumentation tests
./gradlew connectedAndroidTest
```

## Testing

### Automated Tests
- **Integration Tests**: `OverlayIntegrationTest.kt` validates complete pipeline
- **Command Parsing**: Tests all command variants and error handling
- **Touch Visualization**: Verifies gesture feedback system

```bash
# Run integration tests
./gradlew connectedAndroidTest --tests "*OverlayIntegrationTest"
```

### Manual Testing
See [TESTING_GUIDE.md](TESTING_GUIDE.md) for comprehensive manual test steps including:
- Overlay persistence across apps
- Touch visualization accuracy
- OCR functionality
- Command execution pipeline
- Edge cases and error handling

## Architecture Details

### Overlay Service Lifecycle
```
MainActivity ‚Üí Request Permissions ‚Üí Launch OverlayService
    ‚Üì
WindowManager.addView() ‚Üí TYPE_APPLICATION_OVERLAY
    ‚Üì
ComposeView ‚Üí OverlayView ‚Üí GestureOverlayView
    ‚Üì
BroadcastReceiver ‚Üê Commands ‚Üê AccessibilityService
```

### Command Execution Flow
```
Broadcast Command ‚Üí OverlayService.onStartCommand()
    ‚Üì
OverlayViewModel.updateStatus() ‚Üí StateFlow ‚Üí Compose Recomposition
    ‚Üì
CommandProcessor.parseCommand() ‚Üí Command.Tap/Swipe/Scroll
    ‚Üì
CommandExecutor.executeCommand() ‚Üí AccessibilityService.dispatchGesture()
    ‚Üì
GestureOverlayView.showTouch()/showSwipe() ‚Üí Visual Feedback
```

## Troubleshooting

### Overlay Not Visible
- Verify `SYSTEM_ALERT_WINDOW` permission granted in Settings ‚Üí Apps ‚Üí Special access
- Check logcat for `OverlayService` initialization errors

### Commands Not Executing
- Ensure Accessibility Service is enabled in Settings ‚Üí Accessibility
- Check if target app is blocking accessibility events

### OCR Not Working
- Update Google Play Services for ML Kit compatibility
- Verify internet connectivity for ML Kit initialization

## Future Enhancements

- **AI Integration**: Connect Gemini API for intelligent command generation
- **Gesture Recording**: Record and replay complex gesture sequences
- **Multi-device Sync**: Coordinate automation across multiple devices
- **Plugin System**: Extensible command types and visualizations

## License

This project provides a complete overlay and automation framework for Android applications using modern Android development practices with Kotlin, Jetpack Compose, and Accessibility APIs.
